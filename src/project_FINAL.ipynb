{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions 1 is \"s\", -1 is \"b\"\n",
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 138.47 ,   51.655,   97.827, ...,    1.24 ,   -2.475,  113.497],\n",
       "       [ 160.937,   68.768,  103.235, ..., -999.   , -999.   ,   46.226],\n",
       "       [-999.   ,  162.172,  125.953, ..., -999.   , -999.   ,   44.251],\n",
       "       ...,\n",
       "       [ 105.457,   60.526,   75.839, ..., -999.   , -999.   ,   41.992],\n",
       "       [  94.951,   19.362,   68.812, ..., -999.   , -999.   ,    0.   ],\n",
       "       [-999.   ,   72.756,   70.831, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tX.shape)\n",
    "tX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0, freq 0.152456\n",
      "Row 1, freq 0.0\n",
      "Row 2, freq 0.0\n",
      "Row 3, freq 0.0\n",
      "Row 4, freq 0.709828\n",
      "Row 5, freq 0.709828\n",
      "Row 6, freq 0.709828\n",
      "Row 7, freq 0.0\n",
      "Row 8, freq 0.0\n",
      "Row 9, freq 0.0\n",
      "Row 10, freq 0.0\n",
      "Row 11, freq 0.0\n",
      "Row 12, freq 0.709828\n",
      "Row 13, freq 0.0\n",
      "Row 14, freq 0.0\n",
      "Row 15, freq 0.0\n",
      "Row 16, freq 0.0\n",
      "Row 17, freq 0.0\n",
      "Row 18, freq 0.0\n",
      "Row 19, freq 0.0\n",
      "Row 20, freq 0.0\n",
      "Row 21, freq 0.0\n",
      "Row 22, freq 0.0\n",
      "Row 23, freq 0.399652\n",
      "Row 24, freq 0.399652\n",
      "Row 25, freq 0.399652\n",
      "Row 26, freq 0.709828\n",
      "Row 27, freq 0.709828\n",
      "Row 28, freq 0.709828\n",
      "Row 29, freq 0.0\n",
      "112.406\n",
      "2.107\n",
      "225.885\n",
      "-0.244\n",
      "65.561\n",
      "47.902\n"
     ]
    }
   ],
   "source": [
    "from clean_data import *\n",
    "\n",
    "# save ind_delete to delete indices from test data\n",
    "tX_clean, ind_delete = update_X(tX, bound_delete=0.9, bound_change=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_expand_data import *\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, y_train, X_test, y_test = split_data(tX_clean, y, split_ratio=0.7)\n",
    "\n",
    "# store d to later use with real test set\n",
    "d=8\n",
    "\n",
    "# create expanded X_train and X_test and normalize\n",
    "X_train_poly, mu_train_poly, std_train_poly = expand_and_normalize_X(X_train,d)\n",
    "X_test_poly  = expand_X(X_test,d)\n",
    "X_test_poly[:,1:]  = (X_test_poly[:,1:]-mu_train_poly)/std_train_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I - Least Squares GD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41122017806504824\n"
     ]
    }
   ],
   "source": [
    "from least_squares_GD import *\n",
    "\n",
    "initial_w = np.random.normal(0, 1e-1, X_train_poly.shape[1])\n",
    "max_iters = 300\n",
    "gamma = 0.008\n",
    "\n",
    "w, loss = least_squares_GD(y_train, X_train_poly, initial_w, max_iters, gamma)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II Least Squares SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9715214812097751\n"
     ]
    }
   ],
   "source": [
    "# I think this is shitty cause we have 72 params so needs param optimization\n",
    "\n",
    "from least_squares_SGD import *\n",
    "\n",
    "initial_w = np.random.normal(0, 1e-1, X_train_poly.shape[1])\n",
    "max_iters = 100\n",
    "gamma = 0.001\n",
    "\n",
    "w, loss = least_squares_SGD(y_train, X_train_poly, initial_w, max_iters, gamma)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28039029339137816\n",
      "0.4324021634665055\n"
     ]
    }
   ],
   "source": [
    "from least_squares import *\n",
    "\n",
    "w, loss_analytical = least_squares(y_train, X_train_poly)\n",
    "\n",
    "print(loss_analytical)\n",
    "\n",
    "print(compute_loss_mse(y_test, X_test_poly, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    # ***************************************************\n",
    "    N = tx.shape[0]\n",
    "    lambda_prim = 2 * N * lambda_\n",
    "    w = np.linalg.solve(tx.T@tx + lambda_prim * np.eye(tx.shape[1]), tx.T@y)\n",
    "    loss = compute_loss_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-5, 0, 15)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data, and return train and test data: TODO\n",
    "    # ***************************************************\n",
    "    x_train, y_train, x_test, y_test = split_data(x.reshape(-1,1), y, ratio, seed)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # form train and test data with polynomial basis function: TODO\n",
    "    # ***************************************************\n",
    "    x_train_poly = expand_X(x_train.reshape(-1,1), degree)\n",
    "    x_test_poly = expand_X(x_test.reshape(-1,1), degree)\n",
    "\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # ridge regression with a given lambda\n",
    "        # ***************************************************\n",
    "        w = ridge_regression(y_train, x_train_poly, lambda_)[0]\n",
    "        rmse_tr.append(np.sqrt(2 * compute_loss_mse(y_train, x_train_poly, w)))\n",
    "        rmse_te.append(np.sqrt(2 * compute_loss_mse(y_test, x_test_poly, w)))\n",
    "        print(\"proportion={p}, degree={d}, lambda={l:.3f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "               p=ratio, d=degree, l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "        \n",
    "    # Plot the obtained results\n",
    "    plot_train_test(rmse_tr, rmse_te, lambdas, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test(train_errors, test_errors, lambdas, degree):\n",
    "    \"\"\"\n",
    "    train_errors, test_errors and lambas should be list (of the same size) the respective train error and test error for a given lambda,\n",
    "    * lambda[0] = 1\n",
    "    * train_errors[0] = RMSE of a ridge regression on the train set\n",
    "    * test_errors[0] = RMSE of the parameter found by ridge regression applied on the test set\n",
    "    \n",
    "    degree is just used for the title of the plot.\n",
    "    \"\"\"\n",
    "    plt.semilogx(lambdas, train_errors, color='b', marker='*', label=\"Train error\")\n",
    "    plt.semilogx(lambdas, test_errors, color='r', marker='*', label=\"Test error\")\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"Ridge regression for polynomial degree \" + str(degree))\n",
    "    leg = plt.legend(loc=1, shadow=True)\n",
    "    leg.draw_frame(False)\n",
    "    plt.savefig(\"ridge_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.000, Training RMSE=0.297, Testing RMSE=0.298\n",
      "lambda=0.000, Training RMSE=0.298, Testing RMSE=0.298\n",
      "lambda=0.000, Training RMSE=0.298, Testing RMSE=0.299\n",
      "lambda=0.000, Training RMSE=0.299, Testing RMSE=0.299\n",
      "lambda=0.000, Training RMSE=0.299, Testing RMSE=0.300\n",
      "lambda=0.001, Training RMSE=0.300, Testing RMSE=0.301\n",
      "lambda=0.001, Training RMSE=0.301, Testing RMSE=0.302\n",
      "lambda=0.001, Training RMSE=0.302, Testing RMSE=0.303\n",
      "lambda=0.002, Training RMSE=0.303, Testing RMSE=0.305\n",
      "lambda=0.003, Training RMSE=0.305, Testing RMSE=0.307\n",
      "lambda=0.004, Training RMSE=0.306, Testing RMSE=0.308\n",
      "lambda=0.005, Training RMSE=0.307, Testing RMSE=0.309\n",
      "lambda=0.008, Training RMSE=0.309, Testing RMSE=0.310\n",
      "lambda=0.011, Training RMSE=0.311, Testing RMSE=0.312\n",
      "lambda=0.016, Training RMSE=0.313, Testing RMSE=0.313\n",
      "lambda=0.023, Training RMSE=0.315, Testing RMSE=0.315\n",
      "lambda=0.034, Training RMSE=0.318, Testing RMSE=0.318\n",
      "lambda=0.048, Training RMSE=0.321, Testing RMSE=0.321\n",
      "lambda=0.070, Training RMSE=0.324, Testing RMSE=0.324\n",
      "lambda=0.100, Training RMSE=0.328, Testing RMSE=0.328\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-4, -1, 20)\n",
    "\n",
    "ws = []\n",
    "rmse_tr = []\n",
    "rmse_te = []\n",
    "\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # ridge regression with a given lambda\n",
    "        # ***************************************************\n",
    "        ws.append(ridge_regression(y_train, X_train_poly, lambda_)[0])\n",
    "        rmse_tr.append(compute_loss_mse(y_train, X_train_poly, ws[ind]))\n",
    "        rmse_te.append(compute_loss_mse(y_test, X_test_poly, ws[ind]))\n",
    "        print(\"lambda={l:.3f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "               l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.0000001000, Loss sigmoid=98980.363\n",
      "lambda=0.0000005623, Loss sigmoid=88212.407\n",
      "lambda=0.0000031623, Loss sigmoid=81957.533\n",
      "lambda=0.0000177828, Loss sigmoid=inf\n",
      "lambda=0.0001000000, Loss sigmoid=inf\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "from logistic_regression import *\n",
    "\n",
    "y_train_log = y_train\n",
    "y_test_log = y_test\n",
    "\n",
    "y_train_log[y_train == -1] = 0\n",
    "y_test_log[y_test == -1] = 0\n",
    "\n",
    "\n",
    "max_iters = 80\n",
    "initial_w = np.random.normal(0, 1e-4, X_train_poly.shape[1])\n",
    "lambdas = np.logspace(-7, -4, 5)\n",
    "\n",
    "# for lambda_ in lambdas\n",
    "ws = []\n",
    "losses = []\n",
    "\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "    w, loss = logistic_regression(y_train_log, X_train_poly, initial_w, max_iters, lambda_)\n",
    "    ws.append(w)\n",
    "    losses.append(loss)\n",
    "    print(\"lambda={l:.10f}, Loss sigmoid={loss:.3f}\".format(\n",
    "               l=lambda_, loss=losses[ind]))\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A)* Cross Validation (do we need it???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_indices(num_examples,k_fold):\n",
    "    \"\"\"\n",
    "    Splits data indices\n",
    "    num_examples: total samples in the dataset\n",
    "    k_fold: number fold of Cross Validation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    array of shuffled indices with shape (k_fold, num_examples//k_fold)\n",
    "    \"\"\"\n",
    "    ind = np.arange(num_examples)\n",
    "    split_size = num_examples//k_fold\n",
    "    \n",
    "    # shuffle data\n",
    "    np.random.shuffle(ind)\n",
    "    \n",
    "    k_fold_indices = []\n",
    "    # Generate k_fold set of indices\n",
    "    k_fold_indices = [ind[k*split_size:(k+1)*split_size] for k in range(k_fold)]\n",
    "         \n",
    "    return np.array(k_fold_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions based on w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers\n",
    "\n",
    "p = predict_labels(w, X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 81.1 %\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy: %.1f %%' % (np.mean(p == y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1e-07\n",
      "Train Accuracy: 72.3 %\n",
      "Lambda: 5.62341325190349e-07\n",
      "Train Accuracy: 73.4 %\n",
      "Lambda: 3.162277660168379e-06\n",
      "Train Accuracy: 75.3 %\n",
      "Lambda: 1.778279410038923e-05\n",
      "Train Accuracy: 70.9 %\n",
      "Lambda: 0.0001\n",
      "Train Accuracy: 72.1 %\n"
     ]
    }
   ],
   "source": [
    "# check for lambdas\n",
    "\n",
    "for i, w in enumerate(ws):\n",
    "    p = np.where(X_test_poly@w > 0.5, 1, 0)\n",
    "    print(\"Lambda: {}\".format(lambdas[i]))\n",
    "    print('Train Accuracy: %.1f %%' % (np.mean(p == y_test_log) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.0001\n",
      "Train Accuracy: 79.4 %\n",
      "Lambda: 0.0001438449888287663\n",
      "Train Accuracy: 79.4 %\n",
      "Lambda: 0.00020691380811147902\n",
      "Train Accuracy: 79.3 %\n",
      "Lambda: 0.00029763514416313193\n",
      "Train Accuracy: 79.2 %\n",
      "Lambda: 0.00042813323987193956\n",
      "Train Accuracy: 79.1 %\n",
      "Lambda: 0.0006158482110660267\n",
      "Train Accuracy: 79.0 %\n",
      "Lambda: 0.0008858667904100823\n",
      "Train Accuracy: 78.9 %\n",
      "Lambda: 0.0012742749857031334\n",
      "Train Accuracy: 78.8 %\n",
      "Lambda: 0.0018329807108324356\n",
      "Train Accuracy: 78.6 %\n",
      "Lambda: 0.0026366508987303583\n",
      "Train Accuracy: 78.5 %\n",
      "Lambda: 0.00379269019073225\n",
      "Train Accuracy: 78.3 %\n",
      "Lambda: 0.005455594781168515\n",
      "Train Accuracy: 78.1 %\n",
      "Lambda: 0.007847599703514606\n",
      "Train Accuracy: 77.9 %\n",
      "Lambda: 0.011288378916846883\n",
      "Train Accuracy: 77.8 %\n",
      "Lambda: 0.01623776739188721\n",
      "Train Accuracy: 77.6 %\n",
      "Lambda: 0.023357214690901212\n",
      "Train Accuracy: 77.3 %\n",
      "Lambda: 0.03359818286283781\n",
      "Train Accuracy: 77.1 %\n",
      "Lambda: 0.04832930238571752\n",
      "Train Accuracy: 76.8 %\n",
      "Lambda: 0.06951927961775606\n",
      "Train Accuracy: 76.5 %\n",
      "Lambda: 0.1\n",
      "Train Accuracy: 76.1 %\n"
     ]
    }
   ],
   "source": [
    "# check for lambdas\n",
    "\n",
    "for i, w in enumerate(ws):\n",
    "    p = predict_labels(w, X_test_poly)\n",
    "    print(\"Lambda: {}\".format(lambdas[i]))\n",
    "    print('Train Accuracy: %.1f %%' % (np.mean(p == y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112.541\n",
      "2.099\n",
      "226.345\n",
      "-0.244\n",
      "65.839\n",
      "48.037\n"
     ]
    }
   ],
   "source": [
    "# tX_test = np.delete(tX_test, ind_delete, axis=1)\n",
    "tX_test = update_outliers(tX_test, [0, 4, 5, 6, 23, 26], [12, 24, 25, 27, 28])\n",
    "\n",
    "tX_test_poly  = expand_X(tX_test,d)\n",
    "tX_test_poly[:,1:]  = (tX_test_poly[:,1:]-mu_train_poly)/std_train_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w, tX_test_poly)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
