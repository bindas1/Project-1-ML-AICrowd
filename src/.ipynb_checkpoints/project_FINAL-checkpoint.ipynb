{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions 1 is \"s\", -1 is \"b\"\n",
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 138.47 ,   51.655,   97.827, ...,    1.24 ,   -2.475,  113.497],\n",
       "       [ 160.937,   68.768,  103.235, ..., -999.   , -999.   ,   46.226],\n",
       "       [-999.   ,  162.172,  125.953, ..., -999.   , -999.   ,   44.251],\n",
       "       ...,\n",
       "       [ 105.457,   60.526,   75.839, ..., -999.   , -999.   ,   41.992],\n",
       "       [  94.951,   19.362,   68.812, ..., -999.   , -999.   ,    0.   ],\n",
       "       [-999.   ,   72.756,   70.831, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tX.shape)\n",
    "tX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_data import *\n",
    "\n",
    "# save ind_delete to delete indices from test data\n",
    "tX, ind_delete = update_X(tX, bound_delete=0.8, bound_change=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_expand_data import *\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, y_train, X_test, y_test = split_data(tX, y, split_ratio=0.8)\n",
    "\n",
    "# store d to later use with real test set\n",
    "d=7\n",
    "\n",
    "# create expanded X_train and X_test and normalize\n",
    "X_train_poly, mu_train_poly, std_train_poly = expand_and_normalize_X(X_train,d)\n",
    "X_test_poly  = expand_X(X_test,d)\n",
    "X_test_poly[:,1:]  = (X_test_poly[:,1:]-mu_train_poly)/std_train_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I - Least Squares GD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41122017806504824\n"
     ]
    }
   ],
   "source": [
    "from least_squares_GD import *\n",
    "\n",
    "initial_w = np.random.normal(0, 1e-1, X_train_poly.shape[1])\n",
    "max_iters = 300\n",
    "gamma = 0.008\n",
    "\n",
    "w, loss = least_squares_GD(y_train, X_train_poly, initial_w, max_iters, gamma)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II Least Squares SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9715214812097751\n"
     ]
    }
   ],
   "source": [
    "# I think this is shitty cause we have 72 params so needs param optimization\n",
    "\n",
    "from least_squares_SGD import *\n",
    "\n",
    "initial_w = np.random.normal(0, 1e-1, X_train_poly.shape[1])\n",
    "max_iters = 100\n",
    "gamma = 0.001\n",
    "\n",
    "w, loss = least_squares_SGD(y_train, X_train_poly, initial_w, max_iters, gamma)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3228801100705618\n"
     ]
    }
   ],
   "source": [
    "from least_squares import *\n",
    "\n",
    "w, loss_analytical = least_squares(y_train, X_train_poly)\n",
    "\n",
    "print(loss_analytical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A)* Cross Validation (do we need it???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_indices(num_examples,k_fold):\n",
    "    \"\"\"\n",
    "    Splits data indices\n",
    "    num_examples: total samples in the dataset\n",
    "    k_fold: number fold of Cross Validation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    array of shuffled indices with shape (k_fold, num_examples//k_fold)\n",
    "    \"\"\"\n",
    "    ind = np.arange(num_examples)\n",
    "    split_size = num_examples//k_fold\n",
    "    \n",
    "    # shuffle data\n",
    "    np.random.shuffle(ind)\n",
    "    \n",
    "    k_fold_indices = []\n",
    "    # Generate k_fold set of indices\n",
    "    k_fold_indices = [ind[k*split_size:(k+1)*split_size] for k in range(k_fold)]\n",
    "         \n",
    "    return np.array(k_fold_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions based on w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers\n",
    "\n",
    "p = predict_labels(w, X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 77.6 %\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy: %.1f %%' % (np.mean(p == y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test = np.delete(tX_test, ind_delete, axis=1)\n",
    "\n",
    "tX_test_poly  = expand_X(tX_test,d)\n",
    "tX_test_poly[:,1:]  = (tX_test_poly[:,1:]-mu_train_poly)/std_train_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w_analytical, tX_test_poly)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
